{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************************\n",
    "<b>Written By:- Aadish Joshi</b>  \n",
    "<b>Date:- April 24, 2019</b>  \n",
    "<b>Topic:- Language Modeling with Ngrams</b>  \n",
    "\n",
    "➢ What are we trying to solve here?  \n",
    "Using probabilistic models called N-grams to predict the next word from the previous n-1 words.  \n",
    "Note that this problem is corpus (data set of the sentences) specific.  \n",
    "\n",
    "➢ Grams refered to number of words taken into consideration. e.g. unigram means occurence of the single word in the corpus. Bigrams means predicting the next word based on 1 previous word. Trigrams mean predicting the next word based on 2 previous words and so on.\n",
    "\n",
    "➢This method is count based. A simple approach uses count.  \n",
    "Count all the unigrams. e.g. count of all the words in the corpus. \n",
    "\n",
    "➢ We’ll call a statistical model that can assess this probability a Language Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************************\n",
    "\n",
    "➢ Consider following corpus  \n",
    "\n",
    "\"The lake is very big. Its water is so transparent that you can see your face clearly. Its water is so transparent that the moon appears even bigger due to reflection\"  \n",
    "\n",
    "How to estimate the probability of the word \"the\" given previous words \"its water is so transparent that\"  \n",
    "\n",
    "We calculate    \n",
    "\n",
    "Count(its water is so transparent that the) = 1\n",
    "and  \n",
    "Count(its water is so transparent that) = 2\n",
    "\n",
    "Hence  \n",
    "\n",
    "P(the | its water is so transparent that ) = Count(its water is so transparent that the) / Count(its water is so transparent that)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************************\n",
    "Unfortunately, for most sequences and for most text collections we won’t get good estimates from this method.  \n",
    "➢ What we’re likely to get is 0. Or worse 0/0.  \n",
    "\n",
    "➢ Let’s use the chain rule of probability  \n",
    "➢And a particularly useful independence assumption.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************************\n",
    "\n",
    "Chain rule of Probability.\n",
    "P(A,B,C,D) = P(A)P(B|A)P(C|A,B)P(D|A,B,C)  \n",
    "\n",
    "Independence Assumption.(Markov Assumption)  \n",
    "That is, the probability in question is independent of its earlier history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************************\n",
    "How to approach this problem  \n",
    "1) Decide Grams. e.g. Bigrams(2word counts), unigrams(1 word count) etc  \n",
    "2) P(wn | wn-1) = Count(wn-1,wn) | count(wn-1)  \n",
    "\n",
    "Coding:  \n",
    "consider the following corpus  \n",
    "\"Sales of the company to return to normalcy. The new products and services contributed to increase revenue.\"  \n",
    "We have to find the bigram estimates of sentence probabilities in the corpus.  \n",
    "\n",
    "Strategy:  \n",
    "0) preprocess the sentences (optional)  \n",
    "1) Count the unigram count  \n",
    "2) count the bigram count  \n",
    "3) find out bigram_count / unigram_count  \n",
    "*************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus = \"Sales of the company to return to normalcy.\\n Sales of the new products and services contributed to increase revenue.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> sales of the company to return to normalcy </s>', '<s> sales of the new products and services contributed to increase revenue </s>']\n"
     ]
    }
   ],
   "source": [
    "def _preprocess(corpus):\n",
    "    \n",
    "    #split courpus into sentences\n",
    "    sentences = corpus.split(\".\")\n",
    "\n",
    "    #add custom start and end tags\n",
    "    data = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        #add custom start and end tags\n",
    "        if sentence != \"\":\n",
    "            \n",
    "            #keep words and digits only\n",
    "            sentence = re.sub(\"[^a-zA-Z\\d]\", \" \", sentence)\n",
    "            \n",
    "            # lower case words\n",
    "            sentence = sentence.lower()\n",
    "            \n",
    "            #add custom start and end tags\n",
    "            sentence = \"<s> \"+ sentence.strip() + \" </s>\"\n",
    "            \n",
    "            #append processed data\n",
    "            data.append(sentence)\n",
    "    \n",
    "    return data\n",
    "    #to generate words from the sentences\n",
    "    \n",
    "data = _preprocess(corpus)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<s>': 2, 'sales': 2, 'of': 2, 'the': 2, 'company': 1, 'to': 3, 'return': 1, 'normalcy': 1, '</s>': 2, 'new': 1, 'products': 1, 'and': 1, 'services': 1, 'contributed': 1, 'increase': 1, 'revenue': 1}\n"
     ]
    }
   ],
   "source": [
    "def _unigrams(data):\n",
    "    #unigrams as a dict to store keys as unigram and values as word occurence\n",
    "    unigrams = {}\n",
    "    \n",
    "    for sentences in data:\n",
    "        \n",
    "        #generate words from sentences\n",
    "        words = sentences.split(\" \")\n",
    "        \n",
    "        #process individual words\n",
    "        for word in words:\n",
    "            \n",
    "            #if keys exists in dict, we increment the count\n",
    "            try:\n",
    "                if unigrams[word] >= 1:\n",
    "                    unigrams[word] += 1\n",
    "            #else we store key in dict, with cont 1\n",
    "            except:\n",
    "                unigrams[word] = 1\n",
    "    return unigrams\n",
    "\n",
    "unigrams = _unigrams(data)\n",
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('<s>', 'sales'): 2, ('sales', 'of'): 2, ('of', 'the'): 2, ('the', 'company'): 1, ('company', 'to'): 1, ('to', 'return'): 1, ('return', 'to'): 1, ('to', 'normalcy'): 1, ('normalcy', '</s>'): 1, ('the', 'new'): 1, ('new', 'products'): 1, ('products', 'and'): 1, ('and', 'services'): 1, ('services', 'contributed'): 1, ('contributed', 'to'): 1, ('to', 'increase'): 1, ('increase', 'revenue'): 1, ('revenue', '</s>'): 1}\n"
     ]
    }
   ],
   "source": [
    "def _bigrams(data):\n",
    "    #unigrams as a dict to store keys as unigram and values as word occurence\n",
    "    bigrams = {}\n",
    "    \n",
    "    bigram_key_set = []\n",
    "    \n",
    "    for sentences in data:\n",
    "        #generate words from sentences\n",
    "        words = sentences.split(\" \")\n",
    "        \n",
    "        #append bigrams of the words using zip function\n",
    "        bigram_key_set.extend(list(zip(words, words[1:])))\n",
    "        #print(bigram_key_set)\n",
    "                \n",
    "        \n",
    "    for key in bigram_key_set:\n",
    "        try:\n",
    "            if bigrams[key] >= 1:\n",
    "                bigrams[key] += 1\n",
    "        except:\n",
    "            bigrams[key] = 1\n",
    "    return bigrams\n",
    "\n",
    "bigrams = _bigrams(data)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('<s>', 'sales'): 1.0, ('sales', 'of'): 1.0, ('of', 'the'): 1.0, ('the', 'company'): 0.5, ('company', 'to'): 1.0, ('to', 'return'): 0.33, ('return', 'to'): 1.0, ('to', 'normalcy'): 0.33, ('normalcy', '</s>'): 1.0, ('the', 'new'): 0.5, ('new', 'products'): 1.0, ('products', 'and'): 1.0, ('and', 'services'): 1.0, ('services', 'contributed'): 1.0, ('contributed', 'to'): 1.0, ('to', 'increase'): 0.33, ('increase', 'revenue'): 1.0, ('revenue', '</s>'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "def _probability(unigrams,bigrams):\n",
    "    \n",
    "    probability = {}\n",
    "    \n",
    "    for key in bigrams.keys():\n",
    "        word1 = key[0]\n",
    "        \n",
    "        try:\n",
    "            probability[key] = round(bigrams[key] / unigrams[word1],2)\n",
    "        except:\n",
    "            probability[key] = 0\n",
    "    return probability\n",
    "\n",
    "probability = _probability(unigrams,bigrams)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************************\n",
    "What if the unigram count of any number is zero? Can we divide by zero?  \n",
    "\n",
    "Hence we use smoothing technique called as Laplace add 1 smoothing  \n",
    "We add 1 in the unigram word counts  \n",
    "as we add 1 in the unigram count, total number of words will increase by ( N + Vocabulary count)  \n",
    "Vocubary is nothing but unique words in the sentence  \n",
    "\n",
    "*************************************************************************************************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
